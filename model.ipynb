{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleandataset.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of row*coulmns (681, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"No.of row*coulmns {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1      2     3   4   5   6   7     8   9   10  11  12  13   14   15  \\\n",
       "0  NaN   0   1.00  2.00   3   4   5   6  7.00   8   9  10  11  12   13   14   \n",
       "1  0.0   1  30.83  0.00   1   0  12   7  1.25   1   1   1   0   0  202    0   \n",
       "2  1.0   0  58.67  4.46   1   0  10   3  3.04   1   1   6   0   0   43  560   \n",
       "3  2.0   0  24.50  0.50   1   0  10   3  1.50   1   0   0   0   0  280  824   \n",
       "4  3.0   1  27.83  1.54   1   0  12   7  3.75   1   1   5   1   0  100    3   \n",
       "\n",
       "   16  \n",
       "0  15  \n",
       "1   0  \n",
       "2   0  \n",
       "3   0  \n",
       "4   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>38.42</td>\n",
       "      <td>0.705</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>64.08</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>33.92</td>\n",
       "      <td>1.585</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>18.08</td>\n",
       "      <td>6.750</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>68.67</td>\n",
       "      <td>15.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2       3   4   5   6   7      8   9   10  11  12  13   14    15  16\n",
       "416  38.42   0.705   1   0   1   7  0.375   0   1   2   0   0  225   500   1\n",
       "497  64.08   0.165   1   0   5   2  0.000   1   1   1   0   0  232   100   0\n",
       "530  33.92   1.585   2   2   5   2  0.000   1   0   0   0   0  320     0   1\n",
       "271  18.08   6.750   2   2   9   7  0.040   0   0   0   0   0  140     0   1\n",
       "158  68.67  15.000   1   0   4   8  0.000   1   1  14   0   0    0  3376   0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,1:] # drop first row of index values\n",
    "df = df.sample(frac=1) # shuffle rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into its X and y components\n",
    "X, y = df.values[:,:-1], df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we dont have unseen data splitting the given data into train and test sets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use 10-fold cross validation to estimate accuracy.\n",
    "#This will split our dataset into 10 parts, train on 9 and test on 1 and repeat for all combinations of train-test splits.\n",
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.859807 (0.046605)\n",
      "LDA: 0.870531 (0.051278)\n",
      "KNN: 0.660338 (0.071912)\n",
      "CART: 0.844541 (0.052252)\n",
      "NB: 0.791884 (0.058639)\n",
      "SVM: 0.546087 (0.051273)\n",
      "RFC: 0.885990 (0.043668)\n"
     ]
    }
   ],
   "source": [
    "#We don’t know which algorithms would be good on this problem or what configurations to use. \n",
    "#Evaluation algorithms\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('RFC', RandomForestClassifier(n_estimators=50)))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "    #we get bias with mean/average and variance with standard deviation\n",
    "    #lower mean value, better value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier: 0.8488888888888889\n",
      "\n",
      " Confusion matrix as follows: \n",
      " [[ 87  10]\n",
      " [ 24 104]]\n",
      "\n",
      " Classification report as follows: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.90      0.84        97\n",
      "         1.0       0.91      0.81      0.86       128\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       225\n",
      "   macro avg       0.85      0.85      0.85       225\n",
      "weighted avg       0.86      0.85      0.85       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions logreg\n",
    "predictions = logreg.predict(X_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "\n",
    "print(\"Accuracy of logistic regression classifier:\",accuracy_score(y_test, predictions))\n",
    "print(\"\\n Confusion matrix as follows: \\n\",confusion_matrix(y_test,predictions))\n",
    "print(\"\\n Classification report as follows: \\n\",classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of values for tol and max_iter\n",
    "#tol = tolerance(stopping criteria)\n",
    "tol = [0.01,0.001,0.0001]\n",
    "max_iter = [100,150,200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n",
    "param_grid = dict(tol=tol, max_iter=max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate GridSearchCV with the required parameters\n",
    "# grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# # Fit data to grid_model\n",
    "# grid_model_result = grid_model.fit(X_train, y_train)\n",
    "\n",
    "# # Summarize results\n",
    "# best_score, best_params = grid_model_result.best_score_,grid_model_result.best_params_\n",
    "# print(\"Best: %f using %s\" % (best_score, best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.857456 using {'tol': 0.0001, 'max_iter': 100}\n",
      "Execution time: 0.1723031997680664 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#best accuracy - best hyper parameters selection for train data set\n",
    "\n",
    "random = RandomizedSearchCV(estimator=logreg, param_distributions=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(X_train, y_train)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.844444 using {'tol': 0.001, 'max_iter': 100}\n",
      "Execution time: 0.09047865867614746 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\rishi\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#best accuracy - best hyper parameters selection for test data set\n",
    "random = RandomizedSearchCV(estimator=logreg, param_distributions=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(X_test, y_test)\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a SVM with default parameter values\n",
    "svm_clf = SVC(kernel='linear')\n",
    "\n",
    "# Fit svm_clf to the train set\n",
    "svm_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier: 0.8355555555555556\n",
      "\n",
      " Confusion matrix as follows: \n",
      " [[90  7]\n",
      " [30 98]]\n",
      "\n",
      " Classification report as follows: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83        97\n",
      "         1.0       0.93      0.77      0.84       128\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       225\n",
      "   macro avg       0.84      0.85      0.84       225\n",
      "weighted avg       0.85      0.84      0.84       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions svm\n",
    "predictions = svm_clf.predict(X_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "\n",
    "print(\"Accuracy of logistic regression classifier:\",accuracy_score(y_test, predictions))\n",
    "print(\"\\n Confusion matrix as follows: \\n\",confusion_matrix(y_test,predictions))\n",
    "print(\"\\n Classification report as follows: \\n\",classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
